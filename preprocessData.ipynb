{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the data to train a quantitative field classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will pare down the dataset into what we need to train our naive Bayes model. After dropping some irrelevant data, most of the work is in fitting the varied categories into one of the eight fields on the Arxiv today: physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "PATH = 'Data/arxivMetadata.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(PATH, lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping irrelevant columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by dropping the columns we do not need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi',\n",
       "       'report-no', 'categories', 'license', 'abstract', 'versions',\n",
       "       'update_date', 'authors_parsed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id', 'submitter', 'authors', 'comments','journal-ref',\n",
    "                        'doi', 'report-no', 'license',\n",
    "                        'versions', 'update_date', 'authors_parsed'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'categories', 'abstract'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning each paper to a field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the primary category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it stands, the categories column contains finer information than we want to discern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               hep-ph\n",
       "1        math.CO cs.CG\n",
       "2       physics.gen-ph\n",
       "3              math.CO\n",
       "4      math.CA math.FA\n",
       "5    cond-mat.mes-hall\n",
       "6                gr-qc\n",
       "7    cond-mat.mtrl-sci\n",
       "8             astro-ph\n",
       "9              math.CO\n",
       "Name: categories, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['categories'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After crossverifying with the arxiv listings, we see that when two or more categories are listed, the first category listed is the primary category. Let's pick the primary category out and add it as a column in our dataframe. After this, we see that the overarching category label is located after the final period in the category name, so we pick this out as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['primary'] = df.apply(lambda row: row['categories'].split()[0], axis=1)\n",
    "df['primary'] = df.apply(lambda row: row['primary'].split('.')[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hep-ph', 'math', 'physics', 'cond-mat', 'gr-qc', 'astro-ph',\n",
       "       'hep-th', 'hep-ex', 'nlin', 'q-bio', 'quant-ph', 'cs', 'nucl-th',\n",
       "       'math-ph', 'hep-lat', 'nucl-ex', 'q-fin', 'stat', 'eess', 'econ',\n",
       "       'acc-phys', 'adap-org', 'alg-geom', 'ao-sci', 'atom-ph',\n",
       "       'bayes-an', 'chao-dyn', 'chem-ph', 'cmp-lg', 'comp-gas', 'dg-ga',\n",
       "       'funct-an', 'mtrl-th', 'patt-sol', 'plasm-ph', 'q-alg', 'solv-int',\n",
       "       'supr-con'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['primary'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a field to each category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a good deal of physics categories ending in -ph so we use a regular expression to replace these categories with physics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['primary'] = df['primary'].replace('.*ph$', 'physics', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['physics', 'math', 'cond-mat', 'gr-qc', 'hep-th', 'hep-ex', 'nlin',\n",
       "       'q-bio', 'cs', 'nucl-th', 'hep-lat', 'nucl-ex', 'q-fin', 'stat',\n",
       "       'eess', 'econ', 'acc-phys', 'adap-org', 'alg-geom', 'ao-sci',\n",
       "       'bayes-an', 'chao-dyn', 'cmp-lg', 'comp-gas', 'dg-ga', 'funct-an',\n",
       "       'mtrl-th', 'patt-sol', 'q-alg', 'solv-int', 'supr-con'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['primary'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is now a reasonable amount to classify manually. Some judgement calls were made here about which subcategories belong to which overarching fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "physicsSubjects = ['cond-mat', 'gr-qc', 'hep-th', 'hep-ex', 'nucl-th', 'hep-lat', 'nucl-ex','acc-phys', 'nlin', 'adap-org', \n",
    "                        'ao-sci', 'comp-gas', 'mtrl-th', 'supr-con']\n",
    "mathSubjects = ['alg-geom', 'chao-dyn', 'q-alg', 'solv-int', 'funct-an', 'dg-ga']\n",
    "statSubjects = ['bayes-an', 'patt-sol']\n",
    "csSubjects =  ['cmp-lg'] \n",
    "df['primary'].replace(physicsSubjects, ['physics']*len(physicsSubjects), inplace=True)\n",
    "df['primary'].replace(mathSubjects, ['math']*len(mathSubjects), inplace=True)\n",
    "df['primary'].replace(statSubjects, ['stat']*len(statSubjects), inplace=True)\n",
    "df['primary'].replace(csSubjects, ['cs']*len(csSubjects), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see below, we have now categorized the categories into the desired eight categories. Let's save this list of categories for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['physics', 'math', 'q-bio', 'cs', 'q-fin', 'stat', 'eess', 'econ'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = df['primary'].unique()\n",
    "df['primary'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are currently 2.5 million entries in our dataset, 1.3 million of which are physics papers. We will cut the total down by a factor of 10 and take a stratified sample to balance the data. To do this, we first separate out the data by category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfFramesBySubject = [df.loc[df['primary'] == category] for category in categories]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how much of each class we have to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physics (1324943, 4)\n",
      "math (497592, 4)\n",
      "q-bio (27899, 4)\n",
      "cs (504142, 4)\n",
      "q-fin (10991, 4)\n",
      "stat (48429, 4)\n",
      "eess (47427, 4)\n",
      "econ (6980, 4)\n"
     ]
    }
   ],
   "source": [
    "for frame in listOfFramesBySubject:\n",
    "    print(frame.iloc[0].loc['primary'], frame.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of our classes support 20,000 samples so we will aim to get that. Falling short of this, we will just take every entry of the smaller category in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampledLists = [frame.sample(min(20000, frame.shape[0])) for frame in listOfFramesBySubject]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we package the lists together and save the processed dataset as a pickled file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalList = pd.concat(sampledLists, axis=0)\n",
    "OUTPUT = 'Data/sampledPapers.pickle'\n",
    "totalList.to_pickle(OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
